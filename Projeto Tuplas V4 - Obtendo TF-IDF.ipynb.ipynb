{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connections.mongodb_connector import Mongo_Connector\n",
    "from connections.neo4j_connector import Neo4j_Connector\n",
    "import os\n",
    "from datetime import datetime\n",
    "from gensim import corpora, models, similarities\n",
    "from models.graph_generator import Graph_Generator\n",
    "from models.tuple_extractor import Tuple_Extractor\n",
    "import pickle\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim import corpora, models, similarities\n",
    "from connections.mysql_connector import MySQL_Connector\n",
    "from acessos import read, get_conn, persistir_uma_linha, persistir_multiplas_linhas, replace_df\n",
    "from models.topic_modeling import Topic_Modeling\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "import pandas as pd\n",
    "import operator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm.auto import tqdm  # for notebooks\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_tf_idf(corpus):\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tf_idf = vectorizer.fit_transform(corpus)\n",
    "    tokens_list = vectorizer.get_feature_names()\n",
    "    # print(vectorizer.get_feature_names())\n",
    "    # print(tf_idf.shape)\n",
    "\n",
    "    return tf_idf, tokens_list, vectorizer   \n",
    "\n",
    "def get_sentencas_ids(tag_metodo):\n",
    "    query = '''SELECT DISTINCT sentenca_id FROM grupo_resumo WHERE tag_metodo = \"{}\";'''.format(tag_metodo)\n",
    "    return read(conn, query)\n",
    "\n",
    "def get_tuplas_grupo(sentenca_id, tag_metodo):\n",
    "\n",
    "    query = '''\n",
    "    SELECT * FROM tupla_grupo tg\n",
    "        INNER JOIN \n",
    "            grupo_resumo gr USING(grupo_id)\n",
    "        INNER JOIN \n",
    "            tuplas tu USING(tupla_id, sentenca_id)\n",
    "        WHERE \n",
    "            sentenca_id = {}\n",
    "        AND\n",
    "            tag_metodo = \"{}\";\n",
    "    \n",
    "    '''.format(sentenca_id, tag_metodo)\n",
    "    return read(conn, query)\n",
    "\n",
    "def closest_to_centroid_tuple(group_tuples, tuples_id):\n",
    "    group_centroid = np.mean(group_tuples, axis=0)\n",
    "\n",
    "    candidates = []\n",
    "    for i, group_tuple in enumerate(group_tuples):\n",
    "        euclidean_dist = np.linalg.norm(group_tuple-group_centroid)\n",
    "        candidates.append([i,euclidean_dist])\n",
    "    \n",
    "    \n",
    "    best_tuple = (min(candidates, key=lambda x: x[1]))\n",
    "    tuple_id = tuples_id[best_tuple[0]]\n",
    "    distance = best_tuple[1] \n",
    "    return tuple_id, distance\n",
    "\n",
    "def get_embeddings(embedding_table, sentenca_id, tag_metodo, label):\n",
    "    query = '''\n",
    "    SELECT * \n",
    "        FROM\n",
    "        (\n",
    "            SELECT *, IF(tr.grupo_id is not NULL, \"sim\",\"nao\") as processado\n",
    "                FROM \n",
    "                    {} em \n",
    "                INNER JOIN\n",
    "                    tupla_grupo tg USING(tupla_id)\n",
    "                INNER JOIN \n",
    "                    grupo_resumo gr USING(grupo_id, sentenca_id)\n",
    "                INNER JOIN \n",
    "                    tuplas tu USING(tupla_id, sentenca_id, video_id)\n",
    "                LEFT JOIN\n",
    "                    tupla_representativa tr USING(grupo_id, tupla_id)\n",
    "                WHERE \n",
    "                    sentenca_id = {} AND\n",
    "                    tag_metodo = \"{}\" AND\n",
    "                    label = \"{}\"\n",
    "        ) q\n",
    "        WHERE processado = \"nao\"\n",
    "        \n",
    "    '''.format(embedding_table, sentenca_id, tag_metodo, label)\n",
    "    df_retorno = read(conn, query)\n",
    "    \n",
    "    df_tuplas = df_retorno[['sentenca_id', \"tupla_id\", \"grupo_id\", \"num_grupo\"]]\n",
    "    \n",
    "    df_array = df_retorno.drop(['embedding_id','sentenca_id',\n",
    "                                \"tupla_id\",\"label\", \n",
    "                                \"tupla_completa\",\n",
    "                                \"rel\", \"arg1\", \n",
    "                                \"arg2\",\"video_id\",\n",
    "                                \"tag_metodo\", \"num_grupo\",\n",
    "                               \"processado\" ], axis=1) #Gera um df somente com as dimensões (vetor de caracteristicas)    \n",
    "    \n",
    "    array = df_array.to_numpy() #Transforma o df_array em um numpy array \n",
    "    \n",
    "    series_array =  pd.Series([elemento for elemento in array]) #Gera um serie com cada linha sendo um np array\n",
    "    \n",
    "    df_tuplas['array'] = series_array \n",
    "    return df_tuplas, df_retorno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular Representativas por TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = MySQL_Connector(\"conn_orfeu\")\n",
    "db_name = \"flairs2\"\n",
    "conn = connector.return_conn(db_name)\n",
    "\n",
    "tag_metodo = \"distancia-cosseno-80\"\n",
    "label = \"tupla_completa\"\n",
    "\n",
    "\n",
    "lista_sentId = list(get_sentencas_ids(tag_metodo)['sentenca_id'])\n",
    "\n",
    "lista_representativa = []\n",
    "\n",
    "for sentenca_id in tqdm(lista_sentId):\n",
    "    \n",
    "    \n",
    "    df_tuplas = get_tuplas_grupo(sentenca_id, tag_metodo)\n",
    "    corpus = list(df_tuplas[\"tupla_completa\"])\n",
    "    lista_num_grupos =list(df_tuplas[\"num_grupo\"].unique())\n",
    "    \n",
    "    tf_idf, tokens_list, vectorizer = gerar_tf_idf(corpus)\n",
    "    \n",
    "    series_tf_idf =  pd.Series([elemento.toarray() for elemento in tf_idf])\n",
    "    df_tuplas['tf_idf'] = series_tf_idf \n",
    "    \n",
    "    for num_grupo in lista_num_grupos:\n",
    "        df_grupos = df_tuplas.loc[df_tuplas['num_grupo'] == num_grupo] \n",
    "        \n",
    "        grupo_id =  df_grupos['grupo_id'].iloc[0]\n",
    "      \n",
    "        group_tuples = list(df_grupos['tf_idf'])\n",
    "        tuples_id = list(df_grupos[\"tupla_id\"])\n",
    "        \n",
    "        \n",
    "        tupla_id, _ = closest_to_centroid_tuple(group_tuples, tuples_id)\n",
    "        \n",
    "        dict_result = {\n",
    "            \"grupo_id\":grupo_id,\n",
    "            \"tupla_id\":tupla_id\n",
    "        }\n",
    "        lista_representativa.append(dict_result)\n",
    "\n",
    "        \n",
    "df_representativo = pd.DataFrame(lista_representativa)\n",
    "# replace_df(df_representativo, \"tupla_representativa\",conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular Representativas por BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9323e4cebc3040d8b7624612b1dc4103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Persistencia\n",
      "Infelizmente algo deu errado na inserção (persistir_uma_linha)\n",
      "'numpy.int64' object has no attribute 'translate'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "connector = MySQL_Connector(\"conn_orfeu\")\n",
    "db_name = \"flairs2\"\n",
    "conn = connector.return_conn(db_name)\n",
    "\n",
    "tag_metodo = \"bert-cosseno-80\"\n",
    "label = \"tupla_completa\"\n",
    "embedding_table = \"bert\"\n",
    "\n",
    "lista_sentId = list(get_sentencas_ids(tag_metodo)['sentenca_id'])\n",
    "\n",
    "lista_representativa = []\n",
    "\n",
    "lista_sentId = [969]\n",
    "\n",
    "for sentenca_id in tqdm(lista_sentId):\n",
    "    \n",
    "    df_tuplas, _ = get_embeddings(embedding_table, sentenca_id, tag_metodo, label)\n",
    "    lista_num_grupos =list(df_tuplas[\"num_grupo\"].unique())\n",
    "    \n",
    "    for num_grupo in lista_num_grupos:\n",
    "        df_grupos = df_tuplas.loc[df_tuplas['num_grupo'] == num_grupo] \n",
    "\n",
    "        grupo_id =  df_grupos['grupo_id'].iloc[0]\n",
    "\n",
    "        group_tuples = list(df_grupos['array'])\n",
    "        tuples_id = list(df_grupos[\"tupla_id\"])\n",
    "\n",
    "\n",
    "        tupla_id, _ = closest_to_centroid_tuple(group_tuples, tuples_id)\n",
    "\n",
    "        dict_result = {\n",
    "            \"grupo_id\":grupo_id,\n",
    "            \"tupla_id\":tupla_id\n",
    "        }\n",
    "        lista_representativa.append(dict_result)\n",
    "\n",
    "#     df_representativo['grupo_id'] = df_representativo['grupo_id'].astype(str)\n",
    "#     df_representativo['tupla_id'] = df_representativo['tupla_id'].astype(str)\n",
    "    \n",
    "    df_representativo = pd.DataFrame(lista_representativa)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = MySQL_Connector(\"conn_orfeu\")\n",
    "db_name = \"flairs2\"\n",
    "conn = connector.return_conn(db_name)\n",
    "\n",
    "\n",
    "tag_metodo = \"bert-cosseno-80\"\n",
    "label = \"tupla_completa\"\n",
    "embedding_table = \"bert\"\n",
    "sentenca_id = 1\n",
    "\n",
    "df_tuplas, df_retorno = get_embeddings(embedding_table, sentenca_id, tag_metodo, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Persistencia\n",
      "Sucesso na inserção\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_df(df_representativo, \"tupla_representativa\",conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# list(df_retorno.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
